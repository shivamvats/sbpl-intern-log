I had the first detailed meeting with Max. The monolithic planner is finally
working and I have been able to run a few experiments using the improved MHA
planners. So far, I have tested only on the kitchen environment and the indeed
the improved MHA is a major improvement over the earlier planners. It fails
only in cases in which the end effector is in a very complicated (and
potentially unreachable) configuration. Other than that the kitchen environment
does not have much to offer to test different homotopy classes for the base.
However, the results testify the power of using multiple heuristics and the
ability to use inadmissible heuristics greatly simplifies the process of coming
up with multiple heuristics.

Given a search problem, you want to come up with a heuristic that is as close
as possible to the  optimal. However, finding out the optimal heuristic is of
course intractable, so what we try to do is to come up with good enough
heuristics. The one thing I do not like about the whole process is that we need
to design heuristics manually. Though MHA has made the job of heuristic
designer much simpler, I would still want an algorithm to design the heuristics
for my problem. 

### Some of the important points:

* While designing heuristics, there are two aspects one needs to reason about.
  One is the robot specific features and the other is environment specific
  features.

* Robot specific features stay the same always. For example, the size of the
  robot (whether it is cuboidal or cylindrical, for example) enforce certain
  constraints in the paths that need to be generated. So, while generating
  heuristics, it important to capture these features.

* Environment related features (or constraints) usually vary quite a lot. You
  do not want to create heuristics for a specific map or environment. Rather,
  you should try to have heuristics that understand or solve the lower level
  (dimensional) representation that is common across a class of environments
  and capture the most important aspects (features) of the problem. For
  example, heuristics for office like environments would be different from those
  for open environments.

An interesting effect of Venkat's talk on deep learning immediately prior to
my meeting with Max was that the discussion with him generously included the
possibility of using Learning to compute heuristics. Ideally, after training
the network over a training set of environments, it should be able to come up
with good heuristics for a test environment.

### Some possible research topics:

* A cool idea is of dynamically[1] generating heuristics online. So,
  instead of processing the whole environment in one go, we only resort to
  learning if we get stuck somewhere. We then process the immediate
  neighbourhood of the robot and process it to generate heuristics that are
  dropped some time later.

* Every environment has certain important states or points (islands), i.e, states which
  recur frequently in many trajectories. If somehow, we can zero down on those
  states and create heuristics that navigate through those critical points, the
  performance should improve.

* A similar idea is not to focus on the most common states, but on the
  bottleneck points. So, if we can design good heuristics that navigate through
  the difficult parts of the map, the rest of the trajectory can be computed
  using the common heuristics. Typically, most part of a trajectory is simple
  and it has a couple of hard portions. This approach focusses on generating
  efficient heuristics for the tough parts.


[1] Read the paper on Dynamic MHA.


